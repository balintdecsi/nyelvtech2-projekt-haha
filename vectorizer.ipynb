{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0b84c2d970653190f6ff42325a2892d12c901fcb7d34494d0bbe235517760655c",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b84c2d970653190f6ff42325a2892d12c901fcb7d34494d0bbe235517760655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import vocab_creation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def abstract_concatenator(corpus_path):\n",
    "    \"\"\"Concatenates all individual sentences of the corpus into one list.\"\"\"\n",
    "\n",
    "    abstracts_sents = []\n",
    "    with open(corpus_path) as f:\n",
    "        for line in f:\n",
    "            line_dict = json.loads(line)\n",
    "            abstract = line_dict[\"abstract\"]\n",
    "            abstracts_sents += [ab_sent for ab_sent in abstract]\n",
    "\n",
    "    return abstracts_sents\n",
    "\n",
    "print(abstract_concatenator(\"data\\corpus.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_concatenator(jsonl_path, field_name):\n",
    "    \"\"\"Concatenates all individual sentences of the field of interest in .jsonl into one list.\"\"\"\n",
    "\n",
    "    content_sents = []\n",
    "    with open(jsonl_path) as f:\n",
    "        for line in f:\n",
    "            line_dict = json.loads(line)\n",
    "            content = line_dict[field_name]\n",
    "            if field_name == \"abstract\":\n",
    "                content_sents += [cont_sent for cont_sent in content]\n",
    "            else:\n",
    "                content_sents = content\n",
    "\n",
    "    return content_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content2vec(content_path, content_name, vocab):\n",
    "    \"\"\"Vectorizes all of the sentences of the content (claims or corpus(titles excluded)) into TF-IDF features based on a vocabulary.\"\"\"\n",
    "    content_sents = content_concatenator(content_path, content_name)\n",
    "    tfidf_vectorizer = TfidfVectorizer(lowercase=True, stop_words=\"english\", vocabulary=vocab, dtype=np.float32)\n",
    "    content_vec = tfidf_vectorizer.fit_transform(content_sents)\n",
    "\n",
    "    return content_vec.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = content2vec(\"data\\corpus.jsonl\", \"abstract\", vocab_creation.vocab_creation(\"data\\corpus.jsonl\"))\n",
    "print(type(a), a.shape, a.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbbb(a, *args):\n",
    "    print(a)\n",
    "    if args:\n",
    "        print(args[0])\n",
    "\n",
    "bbbb(3, 4, 5, 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}